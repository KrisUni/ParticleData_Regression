{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bee99cf-db1b-4de8-bea6-6c3a1a9232a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_data(name):\n",
    "    with h5py.File(f'{name}.h5', 'r') as f:\n",
    "        filename = name.split('/')[-1]\n",
    "        return pandas.DataFrame(f[filename][:], dtype=np.float64)\n",
    "\n",
    "train = load_data('C:/Users/Chris Bhysicisd/Desktop/Applied machine learning/Project 1/train')\n",
    "test  = load_data('C:/Users/Chris Bhysicisd/Desktop/Applied machine learning/Project 1/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee37da9e-8e9d-4e7a-992d-b0056a32be5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data set: (162500, 166)\n",
      "Shape of test data set: (160651, 164)\n"
     ]
    }
   ],
   "source": [
    "print (f'Shape of training data set: {train.shape}')\n",
    "print (f'Shape of test data set: {test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34d0a883-3a1c-4947-951b-a7833dac6de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn import tree\n",
    "from sklearn.datasets import load_iris, load_wine\n",
    "from sklearn.metrics import accuracy_score,log_loss\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d517067-2189-47e4-ab18-c859e54a0538",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_variables = ['actualInteractionsPerCrossing', 'averageInteractionsPerCrossing', 'correctedActualMu', 'correctedAverageMu', 'correctedScaledActualMu', 'correctedScaledAverageMu', 'NvtxReco', 'p_nTracks', 'p_pt_track', 'p_eta', 'p_phi', 'p_charge', 'p_qOverP', 'p_z0', 'p_d0', 'p_sigmad0', 'p_d0Sig', 'p_EptRatio', 'p_dPOverP', 'p_z0theta', 'p_etaCluster', 'p_phiCluster', 'p_eCluster', 'p_rawEtaCluster', 'p_rawPhiCluster', 'p_rawECluster', 'p_eClusterLr0', 'p_eClusterLr1', 'p_eClusterLr2', 'p_eClusterLr3', 'p_etaClusterLr1', 'p_etaClusterLr2', 'p_phiClusterLr2', 'p_eAccCluster', 'p_f0Cluster', 'p_etaCalo', 'p_phiCalo', 'p_eTileGap3Cluster', 'p_cellIndexCluster', 'p_phiModCalo', 'p_etaModCalo', 'p_dPhiTH3', 'p_R12', 'p_fTG3', 'p_weta2', 'p_Reta', 'p_Rphi', 'p_Eratio', 'p_f1', 'p_f3', 'p_Rhad', 'p_Rhad1', 'p_deltaEta1', 'p_deltaPhiRescaled2', 'p_TRTPID', 'p_TRTTrackOccupancy', 'p_numberOfInnermostPixelHits', 'p_numberOfPixelHits', 'p_numberOfSCTHits', 'p_numberOfTRTHits', 'p_numberOfTRTXenonHits', 'p_chi2', 'p_ndof', 'p_SharedMuonTrack', 'p_E7x7_Lr2', 'p_E7x7_Lr3', 'p_E_Lr0_HiG', 'p_E_Lr0_LowG', 'p_E_Lr0_MedG', 'p_E_Lr1_HiG', 'p_E_Lr1_LowG', 'p_E_Lr1_MedG', 'p_E_Lr2_HiG', 'p_E_Lr2_LowG', 'p_E_Lr2_MedG', 'p_E_Lr3_HiG', 'p_E_Lr3_LowG', 'p_E_Lr3_MedG', 'p_ambiguityType', 'p_asy1', 'p_author', 'p_barys1', 'p_core57cellsEnergyCorrection', 'p_deltaEta0', 'p_deltaEta2', 'p_deltaEta3', 'p_deltaPhi0', 'p_deltaPhi1', 'p_deltaPhi2', 'p_deltaPhi3', 'p_deltaPhiFromLastMeasurement', 'p_deltaPhiRescaled0', 'p_deltaPhiRescaled1', 'p_deltaPhiRescaled3', 'p_e1152', 'p_e132', 'p_e235', 'p_e255', 'p_e2ts1', 'p_ecore', 'p_emins1', 'p_etconeCorrBitset', 'p_ethad', 'p_ethad1', 'p_f1core', 'p_f3core', 'p_maxEcell_energy', 'p_maxEcell_gain', 'p_maxEcell_time', 'p_maxEcell_x', 'p_maxEcell_y', 'p_maxEcell_z', 'p_nCells_Lr0_HiG', 'p_nCells_Lr0_LowG', 'p_nCells_Lr0_MedG', 'p_nCells_Lr1_HiG', 'p_nCells_Lr1_LowG', 'p_nCells_Lr1_MedG', 'p_nCells_Lr2_HiG', 'p_nCells_Lr2_LowG', 'p_nCells_Lr2_MedG', 'p_nCells_Lr3_HiG', 'p_nCells_Lr3_LowG', 'p_nCells_Lr3_MedG', 'p_pos', 'p_pos7', 'p_poscs1', 'p_poscs2', 'p_ptconeCorrBitset', 'p_ptconecoreTrackPtrCorrection', 'p_r33over37allcalo', 'p_topoetconeCorrBitset', 'p_topoetconecoreConeEnergyCorrection', 'p_topoetconecoreConeSCEnergyCorrection', 'p_weta1', 'p_widths1', 'p_widths2', 'p_wtots1', 'p_e233', 'p_e237', 'p_e277', 'p_e2tsts1', 'p_ehad1', 'p_emaxs1', 'p_fracs1', 'p_DeltaE', 'p_E3x5_Lr0', 'p_E3x5_Lr1', 'p_E3x5_Lr2', 'p_E3x5_Lr3', 'p_E5x7_Lr0', 'p_E5x7_Lr1', 'p_E5x7_Lr2', 'p_E5x7_Lr3', 'p_E7x11_Lr0', 'p_E7x11_Lr1', 'p_E7x11_Lr2', 'p_E7x11_Lr3', 'p_E7x7_Lr0', 'p_E7x7_Lr1' ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05456be1-3c54-4932-90a3-b27d2a366dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[all_variables]\n",
    "y = train['Truth']\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10c5e661-8d09-4ad4-9134-3c3f52faf086",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "15-best feature selection\n",
    "'''\n",
    "KBest = SelectKBest(mutual_info_classif, k=15).fit(X, y)\n",
    "short_feature_names = KBest.get_support(1)\n",
    "X_new = X[X.columns[short_feature_names]] # final features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03841e6f-d069-425c-8093-416f2dbaddf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['p_Reta',\n",
       " 'p_Rphi',\n",
       " 'p_Eratio',\n",
       " 'p_Rhad',\n",
       " 'p_Rhad1',\n",
       " 'p_deltaEta1',\n",
       " 'p_deltaPhiRescaled2',\n",
       " 'p_E7x7_Lr3',\n",
       " 'p_deltaEta2',\n",
       " 'p_ethad',\n",
       " 'p_ethad1',\n",
       " 'p_f3core',\n",
       " 'p_ehad1',\n",
       " 'p_E5x7_Lr3',\n",
       " 'p_E7x11_Lr3']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "make a list of 15 features used\n",
    "'''\n",
    "lista = X_new.columns.tolist()\n",
    "X_test=test[lista]\n",
    "lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddc302b2-1d5e-4336-93f9-95fa6ac6de99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_Reta</th>\n",
       "      <th>p_Rphi</th>\n",
       "      <th>p_Eratio</th>\n",
       "      <th>p_Rhad</th>\n",
       "      <th>p_Rhad1</th>\n",
       "      <th>p_deltaEta1</th>\n",
       "      <th>p_deltaPhiRescaled2</th>\n",
       "      <th>p_E7x7_Lr3</th>\n",
       "      <th>p_deltaEta2</th>\n",
       "      <th>p_ethad</th>\n",
       "      <th>p_ethad1</th>\n",
       "      <th>p_f3core</th>\n",
       "      <th>p_ehad1</th>\n",
       "      <th>p_E5x7_Lr3</th>\n",
       "      <th>p_E7x11_Lr3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.948979</td>\n",
       "      <td>0.959359</td>\n",
       "      <td>0.966417</td>\n",
       "      <td>-0.046782</td>\n",
       "      <td>-0.028112</td>\n",
       "      <td>-0.000695</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>201.940689</td>\n",
       "      <td>-0.000545</td>\n",
       "      <td>-1870.002930</td>\n",
       "      <td>-1123.725952</td>\n",
       "      <td>0.003414</td>\n",
       "      <td>-3632.921143</td>\n",
       "      <td>337.980713</td>\n",
       "      <td>470.177124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.932377</td>\n",
       "      <td>0.840511</td>\n",
       "      <td>0.936768</td>\n",
       "      <td>-0.012263</td>\n",
       "      <td>-0.007378</td>\n",
       "      <td>0.001981</td>\n",
       "      <td>-0.001013</td>\n",
       "      <td>412.321869</td>\n",
       "      <td>0.001674</td>\n",
       "      <td>-574.843201</td>\n",
       "      <td>-345.829071</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>-876.445007</td>\n",
       "      <td>412.321869</td>\n",
       "      <td>460.203613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.919559</td>\n",
       "      <td>0.932751</td>\n",
       "      <td>0.976664</td>\n",
       "      <td>0.254060</td>\n",
       "      <td>0.241843</td>\n",
       "      <td>-0.017685</td>\n",
       "      <td>0.011909</td>\n",
       "      <td>3492.513672</td>\n",
       "      <td>-0.007667</td>\n",
       "      <td>7618.711914</td>\n",
       "      <td>7252.364746</td>\n",
       "      <td>0.045345</td>\n",
       "      <td>18070.835938</td>\n",
       "      <td>3492.513672</td>\n",
       "      <td>3333.052734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.950418</td>\n",
       "      <td>0.951195</td>\n",
       "      <td>0.983606</td>\n",
       "      <td>0.018691</td>\n",
       "      <td>0.014779</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>755.622925</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>684.548950</td>\n",
       "      <td>541.277222</td>\n",
       "      <td>0.004143</td>\n",
       "      <td>2071.589844</td>\n",
       "      <td>921.178040</td>\n",
       "      <td>1127.115356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.933916</td>\n",
       "      <td>0.868344</td>\n",
       "      <td>0.950665</td>\n",
       "      <td>0.039488</td>\n",
       "      <td>0.016250</td>\n",
       "      <td>-0.002194</td>\n",
       "      <td>0.004280</td>\n",
       "      <td>-99.527588</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>1379.716919</td>\n",
       "      <td>567.770386</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>2306.320557</td>\n",
       "      <td>-75.167221</td>\n",
       "      <td>-188.182098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162495</th>\n",
       "      <td>0.927466</td>\n",
       "      <td>0.954334</td>\n",
       "      <td>0.942983</td>\n",
       "      <td>0.003995</td>\n",
       "      <td>-0.001940</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>-0.000205</td>\n",
       "      <td>867.511475</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>164.084869</td>\n",
       "      <td>-79.678810</td>\n",
       "      <td>0.005298</td>\n",
       "      <td>-256.751862</td>\n",
       "      <td>867.511475</td>\n",
       "      <td>748.347656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162496</th>\n",
       "      <td>0.941625</td>\n",
       "      <td>0.879206</td>\n",
       "      <td>0.942396</td>\n",
       "      <td>-0.013569</td>\n",
       "      <td>-0.000841</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.011858</td>\n",
       "      <td>534.195374</td>\n",
       "      <td>-0.000785</td>\n",
       "      <td>-462.635895</td>\n",
       "      <td>-28.658590</td>\n",
       "      <td>0.003244</td>\n",
       "      <td>-104.133392</td>\n",
       "      <td>352.093262</td>\n",
       "      <td>665.589417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162497</th>\n",
       "      <td>0.951824</td>\n",
       "      <td>0.979545</td>\n",
       "      <td>0.956721</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.020649</td>\n",
       "      <td>-0.000838</td>\n",
       "      <td>-0.005443</td>\n",
       "      <td>193.382263</td>\n",
       "      <td>0.000914</td>\n",
       "      <td>511.668976</td>\n",
       "      <td>754.674866</td>\n",
       "      <td>0.004215</td>\n",
       "      <td>2010.042236</td>\n",
       "      <td>287.444580</td>\n",
       "      <td>-13.175649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162498</th>\n",
       "      <td>0.916091</td>\n",
       "      <td>0.951640</td>\n",
       "      <td>0.962126</td>\n",
       "      <td>0.002730</td>\n",
       "      <td>-0.000733</td>\n",
       "      <td>-0.075802</td>\n",
       "      <td>-0.057194</td>\n",
       "      <td>1475.285034</td>\n",
       "      <td>-0.035139</td>\n",
       "      <td>105.687500</td>\n",
       "      <td>-28.383762</td>\n",
       "      <td>0.005570</td>\n",
       "      <td>-141.039429</td>\n",
       "      <td>1426.328613</td>\n",
       "      <td>1512.928101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162499</th>\n",
       "      <td>0.889202</td>\n",
       "      <td>0.799274</td>\n",
       "      <td>0.621731</td>\n",
       "      <td>1.044139</td>\n",
       "      <td>0.668416</td>\n",
       "      <td>-0.034882</td>\n",
       "      <td>0.011694</td>\n",
       "      <td>9031.885742</td>\n",
       "      <td>-0.018450</td>\n",
       "      <td>31571.501953</td>\n",
       "      <td>20210.818359</td>\n",
       "      <td>0.070488</td>\n",
       "      <td>68142.500000</td>\n",
       "      <td>8762.319336</td>\n",
       "      <td>9526.083008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162500 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          p_Reta    p_Rphi  p_Eratio    p_Rhad   p_Rhad1  p_deltaEta1  \\\n",
       "0       0.948979  0.959359  0.966417 -0.046782 -0.028112    -0.000695   \n",
       "1       0.932377  0.840511  0.936768 -0.012263 -0.007378     0.001981   \n",
       "2       0.919559  0.932751  0.976664  0.254060  0.241843    -0.017685   \n",
       "3       0.950418  0.951195  0.983606  0.018691  0.014779     0.001504   \n",
       "4       0.933916  0.868344  0.950665  0.039488  0.016250    -0.002194   \n",
       "...          ...       ...       ...       ...       ...          ...   \n",
       "162495  0.927466  0.954334  0.942983  0.003995 -0.001940     0.000122   \n",
       "162496  0.941625  0.879206  0.942396 -0.013569 -0.000841     0.000140   \n",
       "162497  0.951824  0.979545  0.956721  0.014000  0.020649    -0.000838   \n",
       "162498  0.916091  0.951640  0.962126  0.002730 -0.000733    -0.075802   \n",
       "162499  0.889202  0.799274  0.621731  1.044139  0.668416    -0.034882   \n",
       "\n",
       "        p_deltaPhiRescaled2   p_E7x7_Lr3  p_deltaEta2       p_ethad  \\\n",
       "0                  0.000808   201.940689    -0.000545  -1870.002930   \n",
       "1                 -0.001013   412.321869     0.001674   -574.843201   \n",
       "2                  0.011909  3492.513672    -0.007667   7618.711914   \n",
       "3                  0.000747   755.622925     0.000201    684.548950   \n",
       "4                  0.004280   -99.527588     0.000071   1379.716919   \n",
       "...                     ...          ...          ...           ...   \n",
       "162495            -0.000205   867.511475     0.000795    164.084869   \n",
       "162496             0.011858   534.195374    -0.000785   -462.635895   \n",
       "162497            -0.005443   193.382263     0.000914    511.668976   \n",
       "162498            -0.057194  1475.285034    -0.035139    105.687500   \n",
       "162499             0.011694  9031.885742    -0.018450  31571.501953   \n",
       "\n",
       "            p_ethad1  p_f3core       p_ehad1   p_E5x7_Lr3  p_E7x11_Lr3  \n",
       "0       -1123.725952  0.003414  -3632.921143   337.980713   470.177124  \n",
       "1        -345.829071  0.003056   -876.445007   412.321869   460.203613  \n",
       "2        7252.364746  0.045345  18070.835938  3492.513672  3333.052734  \n",
       "3         541.277222  0.004143   2071.589844   921.178040  1127.115356  \n",
       "4         567.770386  0.000045   2306.320557   -75.167221  -188.182098  \n",
       "...              ...       ...           ...          ...          ...  \n",
       "162495    -79.678810  0.005298   -256.751862   867.511475   748.347656  \n",
       "162496    -28.658590  0.003244   -104.133392   352.093262   665.589417  \n",
       "162497    754.674866  0.004215   2010.042236   287.444580   -13.175649  \n",
       "162498    -28.383762  0.005570   -141.039429  1426.328613  1512.928101  \n",
       "162499  20210.818359  0.070488  68142.500000  8762.319336  9526.083008  \n",
       "\n",
       "[162500 rows x 15 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e111143e-a2ca-4cdb-9185-bc551655e069",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_new\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9c13103-30d0-48e9-9a05-f4d2ef2b9d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 7.5823 - accuracy: 0.7604 - val_loss: 2.3457 - val_accuracy: 0.8772\n",
      "Epoch 2/100\n",
      "3250/3250 [==============================] - 6s 2ms/step - loss: 3.3216 - accuracy: 0.8212 - val_loss: 8.9489 - val_accuracy: 0.8034\n",
      "Epoch 3/100\n",
      "3250/3250 [==============================] - 6s 2ms/step - loss: 2.9459 - accuracy: 0.8297 - val_loss: 5.1371 - val_accuracy: 0.6985\n",
      "Epoch 4/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 2.4247 - accuracy: 0.8334 - val_loss: 1.5260 - val_accuracy: 0.8777\n",
      "Epoch 5/100\n",
      "3250/3250 [==============================] - 6s 2ms/step - loss: 1.7974 - accuracy: 0.8442 - val_loss: 1.5979 - val_accuracy: 0.8283\n",
      "Epoch 6/100\n",
      "3250/3250 [==============================] - 6s 2ms/step - loss: 1.5974 - accuracy: 0.8421 - val_loss: 0.7205 - val_accuracy: 0.8778\n",
      "Epoch 7/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 1.1852 - accuracy: 0.8482 - val_loss: 0.7833 - val_accuracy: 0.8632\n",
      "Epoch 8/100\n",
      "3250/3250 [==============================] - 6s 2ms/step - loss: 0.9583 - accuracy: 0.8517 - val_loss: 0.5367 - val_accuracy: 0.8972\n",
      "Epoch 9/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.7792 - accuracy: 0.8581 - val_loss: 0.4383 - val_accuracy: 0.8973\n",
      "Epoch 10/100\n",
      "3250/3250 [==============================] - 6s 2ms/step - loss: 0.5895 - accuracy: 0.8653 - val_loss: 1.9460 - val_accuracy: 0.8130\n",
      "Epoch 11/100\n",
      "3250/3250 [==============================] - 6s 2ms/step - loss: 0.4222 - accuracy: 0.8801 - val_loss: 0.3385 - val_accuracy: 0.8965\n",
      "Epoch 12/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.4017 - accuracy: 0.8824 - val_loss: 0.3248 - val_accuracy: 0.8944\n",
      "Epoch 13/100\n",
      "3250/3250 [==============================] - 6s 2ms/step - loss: 0.3352 - accuracy: 0.8928 - val_loss: 0.3279 - val_accuracy: 0.8911\n",
      "Epoch 14/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3250 - accuracy: 0.8951 - val_loss: 0.3120 - val_accuracy: 0.8995\n",
      "Epoch 15/100\n",
      "3250/3250 [==============================] - 6s 2ms/step - loss: 0.3232 - accuracy: 0.8948 - val_loss: 0.3077 - val_accuracy: 0.8989\n",
      "Epoch 16/100\n",
      "3250/3250 [==============================] - 6s 2ms/step - loss: 0.3194 - accuracy: 0.8954 - val_loss: 0.3153 - val_accuracy: 0.8941\n",
      "Epoch 17/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3187 - accuracy: 0.8958 - val_loss: 0.3125 - val_accuracy: 0.8974\n",
      "Epoch 18/100\n",
      "3250/3250 [==============================] - 6s 2ms/step - loss: 0.3164 - accuracy: 0.8963 - val_loss: 0.3061 - val_accuracy: 0.9002\n",
      "Epoch 19/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3134 - accuracy: 0.8969 - val_loss: 0.5487 - val_accuracy: 0.8329\n",
      "Epoch 20/100\n",
      "3250/3250 [==============================] - 6s 2ms/step - loss: 0.3143 - accuracy: 0.8970 - val_loss: 0.3052 - val_accuracy: 0.8982\n",
      "Epoch 21/100\n",
      "3250/3250 [==============================] - 6s 2ms/step - loss: 0.3133 - accuracy: 0.8964 - val_loss: 0.3072 - val_accuracy: 0.8985\n",
      "Epoch 22/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3132 - accuracy: 0.8970 - val_loss: 0.3202 - val_accuracy: 0.8954\n",
      "Epoch 23/100\n",
      "3250/3250 [==============================] - 6s 2ms/step - loss: 0.3173 - accuracy: 0.8956 - val_loss: 0.3068 - val_accuracy: 0.9000\n",
      "Epoch 24/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3124 - accuracy: 0.8974 - val_loss: 0.3191 - val_accuracy: 0.8902\n",
      "Epoch 25/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3142 - accuracy: 0.8967 - val_loss: 0.3074 - val_accuracy: 0.8997\n",
      "Epoch 26/100\n",
      "3250/3250 [==============================] - 6s 2ms/step - loss: 0.3173 - accuracy: 0.8973 - val_loss: 0.3059 - val_accuracy: 0.9009\n",
      "Epoch 27/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3115 - accuracy: 0.8968 - val_loss: 0.3089 - val_accuracy: 0.8962\n",
      "Epoch 28/100\n",
      "3250/3250 [==============================] - 6s 2ms/step - loss: 0.3117 - accuracy: 0.8973 - val_loss: 0.3109 - val_accuracy: 0.8987\n",
      "Epoch 29/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3136 - accuracy: 0.8967 - val_loss: 0.3112 - val_accuracy: 0.8987\n",
      "Epoch 30/100\n",
      "3250/3250 [==============================] - 6s 2ms/step - loss: 0.3123 - accuracy: 0.8975 - val_loss: 0.3043 - val_accuracy: 0.9012\n",
      "Epoch 31/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3142 - accuracy: 0.8968 - val_loss: 0.3059 - val_accuracy: 0.8997\n",
      "Epoch 32/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3117 - accuracy: 0.8972 - val_loss: 0.3189 - val_accuracy: 0.9001\n",
      "Epoch 33/100\n",
      "3250/3250 [==============================] - 6s 2ms/step - loss: 0.3135 - accuracy: 0.8978 - val_loss: 0.3035 - val_accuracy: 0.9004\n",
      "Epoch 34/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3106 - accuracy: 0.8973 - val_loss: 0.3043 - val_accuracy: 0.9008\n",
      "Epoch 35/100\n",
      "3250/3250 [==============================] - 6s 2ms/step - loss: 0.3151 - accuracy: 0.8966 - val_loss: 0.3032 - val_accuracy: 0.9002\n",
      "Epoch 36/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3122 - accuracy: 0.8978 - val_loss: 0.3020 - val_accuracy: 0.9011\n",
      "Epoch 37/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3120 - accuracy: 0.8973 - val_loss: 0.3135 - val_accuracy: 0.9007\n",
      "Epoch 38/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3127 - accuracy: 0.8981 - val_loss: 0.3081 - val_accuracy: 0.8987\n",
      "Epoch 39/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3120 - accuracy: 0.8980 - val_loss: 0.3098 - val_accuracy: 0.8997\n",
      "Epoch 40/100\n",
      "3250/3250 [==============================] - 6s 2ms/step - loss: 0.3110 - accuracy: 0.8980 - val_loss: 0.3103 - val_accuracy: 0.8967\n",
      "Epoch 41/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3114 - accuracy: 0.8981 - val_loss: 0.3080 - val_accuracy: 0.9008\n",
      "Epoch 42/100\n",
      "3250/3250 [==============================] - 6s 2ms/step - loss: 0.3137 - accuracy: 0.8981 - val_loss: 0.3048 - val_accuracy: 0.9001\n",
      "Epoch 43/100\n",
      "3250/3250 [==============================] - 8s 3ms/step - loss: 0.3144 - accuracy: 0.8973 - val_loss: 0.3023 - val_accuracy: 0.9011\n",
      "Epoch 44/100\n",
      "3250/3250 [==============================] - 6s 2ms/step - loss: 0.3107 - accuracy: 0.8982 - val_loss: 0.3033 - val_accuracy: 0.9009\n",
      "Epoch 45/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3098 - accuracy: 0.8982 - val_loss: 0.3028 - val_accuracy: 0.9005\n",
      "Epoch 46/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3131 - accuracy: 0.8978 - val_loss: 0.3080 - val_accuracy: 0.8968\n",
      "Epoch 47/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3076 - accuracy: 0.8988 - val_loss: 0.3450 - val_accuracy: 0.8936\n",
      "Epoch 48/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3119 - accuracy: 0.8977 - val_loss: 0.3022 - val_accuracy: 0.9015\n",
      "Epoch 49/100\n",
      "3250/3250 [==============================] - 6s 2ms/step - loss: 0.3109 - accuracy: 0.8981 - val_loss: 0.3079 - val_accuracy: 0.9010\n",
      "Epoch 50/100\n",
      "3250/3250 [==============================] - 8s 2ms/step - loss: 0.3104 - accuracy: 0.8984 - val_loss: 0.3116 - val_accuracy: 0.8993\n",
      "Epoch 51/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3125 - accuracy: 0.8978 - val_loss: 0.3073 - val_accuracy: 0.8968\n",
      "Epoch 52/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3120 - accuracy: 0.8974 - val_loss: 0.3115 - val_accuracy: 0.8986\n",
      "Epoch 53/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3122 - accuracy: 0.8981 - val_loss: 0.3088 - val_accuracy: 0.9000\n",
      "Epoch 54/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3120 - accuracy: 0.8980 - val_loss: 0.3134 - val_accuracy: 0.8968\n",
      "Epoch 55/100\n",
      "3250/3250 [==============================] - 6s 2ms/step - loss: 0.3115 - accuracy: 0.8981 - val_loss: 0.3027 - val_accuracy: 0.9010\n",
      "Epoch 56/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3099 - accuracy: 0.8982 - val_loss: 0.3072 - val_accuracy: 0.9012\n",
      "Epoch 57/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3096 - accuracy: 0.8984 - val_loss: 0.3109 - val_accuracy: 0.8981\n",
      "Epoch 58/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3072 - accuracy: 0.8989 - val_loss: 0.3114 - val_accuracy: 0.8987\n",
      "Epoch 59/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3144 - accuracy: 0.8979 - val_loss: 0.3043 - val_accuracy: 0.9004\n",
      "Epoch 60/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3118 - accuracy: 0.8982 - val_loss: 0.3026 - val_accuracy: 0.9007\n",
      "Epoch 61/100\n",
      "3250/3250 [==============================] - 8s 2ms/step - loss: 0.3125 - accuracy: 0.8985 - val_loss: 0.3034 - val_accuracy: 0.9002\n",
      "Epoch 62/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3150 - accuracy: 0.8983 - val_loss: 0.3025 - val_accuracy: 0.9020\n",
      "Epoch 63/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3073 - accuracy: 0.8987 - val_loss: 0.3019 - val_accuracy: 0.9010\n",
      "Epoch 64/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3092 - accuracy: 0.8989 - val_loss: 0.3210 - val_accuracy: 0.8914\n",
      "Epoch 65/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3127 - accuracy: 0.8983 - val_loss: 0.3040 - val_accuracy: 0.9013\n",
      "Epoch 66/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3111 - accuracy: 0.8983 - val_loss: 0.3044 - val_accuracy: 0.8997\n",
      "Epoch 67/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3113 - accuracy: 0.8985 - val_loss: 0.3078 - val_accuracy: 0.9009\n",
      "Epoch 68/100\n",
      "3250/3250 [==============================] - 8s 2ms/step - loss: 0.3105 - accuracy: 0.8981 - val_loss: 0.3108 - val_accuracy: 0.9005\n",
      "Epoch 69/100\n",
      "3250/3250 [==============================] - 6s 2ms/step - loss: 0.3113 - accuracy: 0.8983 - val_loss: 0.3013 - val_accuracy: 0.9013\n",
      "Epoch 70/100\n",
      "3250/3250 [==============================] - 8s 2ms/step - loss: 0.3104 - accuracy: 0.8987 - val_loss: 0.3016 - val_accuracy: 0.9015\n",
      "Epoch 71/100\n",
      "3250/3250 [==============================] - 6s 2ms/step - loss: 0.3076 - accuracy: 0.8991 - val_loss: 0.3004 - val_accuracy: 0.9018\n",
      "Epoch 72/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3096 - accuracy: 0.8987 - val_loss: 0.3054 - val_accuracy: 0.9017\n",
      "Epoch 73/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3092 - accuracy: 0.8984 - val_loss: 0.3011 - val_accuracy: 0.9020\n",
      "Epoch 74/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3070 - accuracy: 0.8988 - val_loss: 0.3028 - val_accuracy: 0.9015\n",
      "Epoch 75/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3082 - accuracy: 0.8990 - val_loss: 0.3031 - val_accuracy: 0.9015\n",
      "Epoch 76/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3076 - accuracy: 0.8992 - val_loss: 0.3092 - val_accuracy: 0.8986\n",
      "Epoch 77/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3087 - accuracy: 0.8982 - val_loss: 0.3090 - val_accuracy: 0.8995\n",
      "Epoch 78/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3079 - accuracy: 0.8990 - val_loss: 0.3025 - val_accuracy: 0.9020\n",
      "Epoch 79/100\n",
      "3250/3250 [==============================] - 8s 2ms/step - loss: 0.3101 - accuracy: 0.8983 - val_loss: 0.3302 - val_accuracy: 0.8905\n",
      "Epoch 80/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3075 - accuracy: 0.8990 - val_loss: 0.3010 - val_accuracy: 0.9012\n",
      "Epoch 81/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3082 - accuracy: 0.8986 - val_loss: 0.3033 - val_accuracy: 0.9021\n",
      "Epoch 82/100\n",
      "3250/3250 [==============================] - 6s 2ms/step - loss: 0.3070 - accuracy: 0.8992 - val_loss: 0.3025 - val_accuracy: 0.9015\n",
      "Epoch 83/100\n",
      "3250/3250 [==============================] - 8s 3ms/step - loss: 0.3091 - accuracy: 0.8988 - val_loss: 0.3049 - val_accuracy: 0.9011\n",
      "Epoch 84/100\n",
      "3250/3250 [==============================] - 6s 2ms/step - loss: 0.3081 - accuracy: 0.8997 - val_loss: 0.3062 - val_accuracy: 0.9007\n",
      "Epoch 85/100\n",
      "3250/3250 [==============================] - 8s 2ms/step - loss: 0.3078 - accuracy: 0.8993 - val_loss: 0.3097 - val_accuracy: 0.8966\n",
      "Epoch 86/100\n",
      "3250/3250 [==============================] - 6s 2ms/step - loss: 0.3086 - accuracy: 0.8991 - val_loss: 0.3006 - val_accuracy: 0.9024\n",
      "Epoch 87/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3068 - accuracy: 0.8991 - val_loss: 0.3016 - val_accuracy: 0.9021\n",
      "Epoch 88/100\n",
      "3250/3250 [==============================] - 8s 2ms/step - loss: 0.3103 - accuracy: 0.8992 - val_loss: 0.3114 - val_accuracy: 0.8977\n",
      "Epoch 89/100\n",
      "3250/3250 [==============================] - 6s 2ms/step - loss: 0.3097 - accuracy: 0.8992 - val_loss: 0.3021 - val_accuracy: 0.9016\n",
      "Epoch 90/100\n",
      "3250/3250 [==============================] - 8s 3ms/step - loss: 0.3062 - accuracy: 0.8995 - val_loss: 0.3043 - val_accuracy: 0.9013\n",
      "Epoch 91/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3092 - accuracy: 0.8986 - val_loss: 0.3037 - val_accuracy: 0.9008\n",
      "Epoch 92/100\n",
      "3250/3250 [==============================] - 8s 2ms/step - loss: 0.3113 - accuracy: 0.8988 - val_loss: 0.3029 - val_accuracy: 0.9013\n",
      "Epoch 93/100\n",
      "3250/3250 [==============================] - 6s 2ms/step - loss: 0.3063 - accuracy: 0.8996 - val_loss: 0.3109 - val_accuracy: 0.9003\n",
      "Epoch 94/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3067 - accuracy: 0.8995 - val_loss: 0.3016 - val_accuracy: 0.9019\n",
      "Epoch 95/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3078 - accuracy: 0.8994 - val_loss: 0.3022 - val_accuracy: 0.9019\n",
      "Epoch 96/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3075 - accuracy: 0.8994 - val_loss: 0.3031 - val_accuracy: 0.9005\n",
      "Epoch 97/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3070 - accuracy: 0.8995 - val_loss: 0.3199 - val_accuracy: 0.8916\n",
      "Epoch 98/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3076 - accuracy: 0.8993 - val_loss: 0.3131 - val_accuracy: 0.8936\n",
      "Epoch 99/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3082 - accuracy: 0.8989 - val_loss: 0.3023 - val_accuracy: 0.9020\n",
      "Epoch 100/100\n",
      "3250/3250 [==============================] - 7s 2ms/step - loss: 0.3081 - accuracy: 0.8995 - val_loss: 0.3096 - val_accuracy: 0.8992\n",
      "1016/1016 [==============================] - 2s 1ms/step\n",
      "1016/1016 [==============================] - 2s 2ms/step - loss: 0.3060 - accuracy: 0.8997\n",
      "[0.30595216155052185, 0.8997230529785156]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "X_test=test[lista]\n",
    "\n",
    "input_dim = len(X_train.columns)\n",
    "\n",
    "neurons = 64\n",
    "epochs = 100\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(neurons, input_dim=input_dim, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=epochs, verbose=1, validation_split=0.2)\n",
    "predictions = model.predict(X_val)\n",
    "\n",
    "\n",
    "\n",
    "scores = model.evaluate(X_val, y_val, verbose=1)\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "122ab4cd-b8f3-4e03-a577-085ee1578a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 1089\n"
     ]
    }
   ],
   "source": [
    "#Get the number of parameters\n",
    "num_parameters = model.count_params()\n",
    "\n",
    "# Print the number of parameters\n",
    "print(\"Number of parameters:\", num_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e625716c-9214-4ab1-98b1-1aa6f901158a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5021/5021 [==============================] - 7s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred =  model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d42ad24-816f-49b7-84d8-e612185f4602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.0165353e-01],\n",
       "       [8.8911432e-01],\n",
       "       [8.9325309e-01],\n",
       "       [9.0165353e-01],\n",
       "       [1.6850144e-01],\n",
       "       [9.0165353e-01],\n",
       "       [9.0165353e-01],\n",
       "       [9.0165353e-01],\n",
       "       [9.0165353e-01],\n",
       "       [9.0165353e-01],\n",
       "       [4.9696597e-03],\n",
       "       [9.0165353e-01],\n",
       "       [9.0165353e-01],\n",
       "       [1.9000391e-03],\n",
       "       [9.0165353e-01],\n",
       "       [9.0165353e-01],\n",
       "       [5.5013103e-08],\n",
       "       [9.0165353e-01],\n",
       "       [9.0165353e-01],\n",
       "       [9.0165353e-01],\n",
       "       [6.3989537e-06],\n",
       "       [9.0165353e-01],\n",
       "       [8.8982046e-01],\n",
       "       [9.0165353e-01],\n",
       "       [9.0165353e-01],\n",
       "       [8.1302917e-01],\n",
       "       [9.0165353e-01],\n",
       "       [9.0165353e-01],\n",
       "       [7.6311415e-05],\n",
       "       [8.2286257e-01],\n",
       "       [9.0165353e-01],\n",
       "       [9.0165353e-01],\n",
       "       [5.1455587e-15],\n",
       "       [9.0165353e-01],\n",
       "       [3.0222135e-02],\n",
       "       [5.4036741e-07],\n",
       "       [1.9761922e-14],\n",
       "       [9.0165353e-01],\n",
       "       [9.0165353e-01],\n",
       "       [9.0165353e-01],\n",
       "       [9.0165353e-01],\n",
       "       [9.0165353e-01],\n",
       "       [9.0165353e-01],\n",
       "       [6.1076054e-07],\n",
       "       [8.4614855e-01],\n",
       "       [9.0165353e-01],\n",
       "       [2.0480636e-01],\n",
       "       [6.7289639e-01],\n",
       "       [8.9930713e-01],\n",
       "       [9.0165353e-01],\n",
       "       [9.0165353e-01],\n",
       "       [9.0165353e-01],\n",
       "       [9.0165353e-01],\n",
       "       [9.0165353e-01],\n",
       "       [9.0165353e-01],\n",
       "       [9.0165353e-01],\n",
       "       [9.0165353e-01],\n",
       "       [2.5460181e-01],\n",
       "       [9.0165353e-01],\n",
       "       [9.0165353e-01],\n",
       "       [9.0165353e-01],\n",
       "       [9.0165353e-01],\n",
       "       [9.0165353e-01],\n",
       "       [9.0165353e-01],\n",
       "       [6.1140531e-01],\n",
       "       [9.2408707e-04],\n",
       "       [3.9967355e-17],\n",
       "       [8.6493737e-01],\n",
       "       [9.0165353e-01],\n",
       "       [9.0165353e-01],\n",
       "       [4.7117177e-01],\n",
       "       [9.0165353e-01],\n",
       "       [9.0165353e-01],\n",
       "       [9.0165353e-01],\n",
       "       [9.0165353e-01],\n",
       "       [8.9363807e-01],\n",
       "       [8.8769394e-01],\n",
       "       [9.0165353e-01],\n",
       "       [3.0784189e-08],\n",
       "       [8.8308871e-01],\n",
       "       [9.0165353e-01],\n",
       "       [9.0165353e-01],\n",
       "       [9.0165353e-01],\n",
       "       [6.5918980e-06],\n",
       "       [9.0165353e-01],\n",
       "       [8.9716816e-01],\n",
       "       [9.0165353e-01],\n",
       "       [5.0245266e-04],\n",
       "       [9.0165353e-01],\n",
       "       [9.0165353e-01],\n",
       "       [3.2715481e-02],\n",
       "       [1.3288562e-12],\n",
       "       [9.0165353e-01],\n",
       "       [3.4457862e-01],\n",
       "       [9.0165353e-01],\n",
       "       [9.0165353e-01],\n",
       "       [9.0165353e-01],\n",
       "       [9.0165353e-01],\n",
       "       [7.3448455e-01],\n",
       "       [8.8043546e-09]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44933ee4-a974-499d-abe4-df2cdbbba202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Generate indices for the index column\n",
    "indices = np.arange(len(y_pred))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Convert indices to a one-dimensional array\n",
    "indices = np.ravel(indices)\n",
    "\n",
    "# Round y_pred to 8 significant digits\n",
    "y_pred_rounded = np.around(y_pred, decimals=8)\n",
    "\n",
    "# Concatenate indices and cluster labels horizontally\n",
    "data_with_index = np.column_stack((indices, y_pred))\n",
    "\n",
    "# Save the data with index to a text file\n",
    "np.savetxt(\"y_pred_NN.txt\", data_with_index, fmt=[\"%d\"] + [\"%.8f\"], delimiter=\",\", header=\"\", comments=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b375213-ca2f-4979-bb97-e41131bab654",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
